# Лабораторные работы №6-8

------------------------------------------------
|  Выполнил    |    Группа       | Дата        |
|--------------|-----------------|-------------|
| Карнаков Н.Д.|    М8О-406Б-21  |   10.05.2025|

## Структура репозитория

[lab6-8MultiMediaSEM8_Final](lab6-8MultiMediaSEM8_Final) - Jupiter-notebook с выполненными лабораторными работами №6-8 

p.s. Добавил новый файл, потому что с тем что-то случилось... пытаюсь восстановить

upd. Добавил файл final с тем, что удалось восстановить

[README.md](README.md) - Краткий отчет о проделанной работе

## Лабораторная работа №6 (Проведение исследований с моделями классификации)

Используемый датасет для задачи классификации - https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia

### Сравнительная таблица 

| Модель                             | Accuracy  | Precision | Recall   | F1-score | ROC-AUC  | PR-AUC   |
| ---------------------------------- | --------- | --------- | -------- | -------- | -------- | -------- |
| ResNet18 (baseline)                | 0.782051  | 0.746124  | 0.987179 | 0.849890 | 0.944587 | 0.959907 |
| ViT-B_16 (baseline)                | 0.727564  | 0.701465  | 0.982051 | 0.818376 | 0.932807 | 0.958099 |
| ResNet18 (improved)                | 0.931093  | 0.914081  | 0.982051 | 0.946848 | 0.975093 | 0.983458 |
| ViT-B_16 (improved)                | 0.868590  | 0.955621  | 0.828205 | 0.887363 | 0.960618 | 0.973207 |
| CustomCNN (baseline)               | 0.716346  | 0.689840  | 0.992308 | 0.813880 | 0.843809 | 0.854794 |
| CustomCNN (improved)               | 0.504808  | 0.987952  | 0.210256 | 0.346723 | 0.898619 | 0.933004 |
| Custom ViT (baseline)              | 0.625000  | 0.625000  | 1.000000 | 0.769231 | 0.500000 | 0.625000 |
| Custom ViT (improved)              | 0.625000  | 0.625000  | 1.000000 | 0.769231 | 0.500000 | 0.625000 |

### Вывод

На основе всестороннего эксперимента с восемью моделями для задачи бинарной классификации рентгеновских снимков лёгких была выявлена чёткая зависимость между предобученной архитектурой и объёмом обучающей выборки, а также эффективностью прикладных приёмов улучшения качества.

Во-первых, модели ResNet-18 и ViT-B_16, предобученные на ImageNet и использованные в качестве бейзлайна, продемонстрировали высокую базовую производительность: ResNet-18 показала сбалансированные метрики (accuracy ≈ 78 %, recall ≈ 99 %, precision ≈ 75 %, F1 ≈ 85 %), а ViT-B_16 чуть уступала ей по F1 (≈ 82 %), но уже обладала преимущественно высокой способностью к разделению классов (ROC-AUC ≈ 93 %). Применение комплекса улучшений — расширенные аугментации, взвешенная функция потерь и управление скоростью обучения через LR-scheduler — позволило ResNet-18 достичь accuracy ≈ 93 %, recall ≈ 98 % и precision ≈ 91 % (F1 ≈ 95 %), тогда как ViT-B_16 (improved) повысил precision до ≈ 96 % при F1 ≈ 89 %. Данные результаты подчёркивают, что предобученные на больших корпусах изображения CNN и трансформеры наиболее адекватно адаптируются к медицинским изображениям после донастройки.

Во-вторых, самостоятельная разработка сверточной нейронной сети (CustomCNN) с четырьмя блоками и двумя полносвязными слоями, обученная «с нуля» на том же ограниченном объёме данных, продемонстрировала высокий recall (≈ 99 %) за счёт массовых ложных срабатываний (precision ≈ 69 %, F1 ≈ 81 %), что свидетельствует о её склонности к максимизации полноты при минимальных объёмах. Попытка усилить модель аналогичным комплексом улучшений привела к обратному эффекту: precision возрос до ≈ 99 %, а recall упал до ≈ 21 %, что говорит о чрезмерной осторожности классификатора при отсутствии достаточной обучающей выборки.

В-третьих, собственная реализация Vision Transformer также показала крайне ограниченные возможности при обучении «с нуля» на 10 % данных: базовый Custom ViT практически всегда предсказывал один класс (accuracy ≈ 62 %, ROC-AUC = 0.5), а внесённые улучшения оказались бессильны сместить эту стагнацию. Это подчёркивает важность предобучения трансформеров на масштабных наборах данных и необходимости существенно большего объёма разнообразных медицинских изображений для их успешной адаптации.

Таким образом, результаты всего исследования позволяют заключить, что для задач классификации медицинских изображений при ограниченном объёме аннотированных данных оптимальным выбором являются предобученные архитектуры (ResNet, ViT) с дальнейшей донастройкой на целевом домене с применением техники аугментаций, балансировки классов и адаптивного изменения learning rate. Собственные модели без предобучения демонстрируют недостаточную способность к генерализации или, напротив, слишком радикальные компромиссы между recall и precision. Для дальнейшего улучшения качества классификации рекомендуется расширять аннотированные датасеты, использовать ансамбли предобученных архитектур и внедрять пороговую оптимизацию для достижения необходимого баланса между ошибками первого и второго рода.

## Лабораторная работа №7 (Проведение исследований моделями семантической сегментации).

Используемый датасет - https://www.kaggle.com/datasets/bulentsiyah/semantic-drone-dataset

### Сравнительная таблица 

<table>
    <thead>
        <tr>
            <th rowspan=2>Модель</th>
            <th colspan=2>Accuracy</th>
            <th colspan=2>IoU</th>
            <th colspan=2>Dice</th>
        </tr>
        <tr>
            <th>baseline</th>
            <th>improved</th>
            <th>baseline</th>
            <th>improved</th>
            <th>baseline</th>
            <th>improved</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><b><i>U-Net</i></b></td>
            <td>0.757</td>
            <td>0.872</td>
            <td>0.349</td>
            <td>0.480</td>
            <td>0.439</td>
            <td>0.566</td>
        </tr>
        <tr>
            <td><b><i>U-Net (собственной реализации)</i></b></td>
            <td>0.790</td>
            <td>0.782</td>
            <td>0.361</td>
            <td>0.317</td>
            <td>0.444</td>
            <td>0.374</td>
        </tr>
    </tbody>
</table>

### Вывод

Результаты продемонстрировали, что наилучшие показатели точности в задаче семантической сегментации были достигнуты с использованием U-Net с энкодером ResNet50. При собственной реализации и обучении стандартного базового алгоритма удалось превзойти U-Net с ResNet34, однако дальнейших улучшений базового решения добиться не удалось. Несмотря на снижение функции потерь и рост значений ключевых метрик в процессе обучения, существенного прироста точности не произошло. Следовало бы усложнить архитектуру модели, учитывая её изначальную простоту, а также провести более детальную оптимизацию гиперпараметров.

---

## Лабораторная работа №8 (Проведение исследований моделями обнаружения и распознавания объектов).

Используемый датасет - https://www.kaggle.com/datasets/sshikamaru/car-object-detection

### Сравнительная таблица 

<table>
    <thead>
        <tr>
            <th>Модель</th>
            <th>Precision</th>
            <th>Recall</th>
            <th>mAP50</th>
            <th>mAP50-95</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><b><i>YOLOv11</i></b></td>
            <td>0.848</td>
            <td>0.702</td>
            <td>0.786</td>
            <td>0.494</td>
        </tr>
        <tr>
            <td><b><i>YOLOv11 improved</i></b></td>
            <td>0.901</td>
            <td>0.709</td>
            <td>0.800</td>
            <td>0.512</td>
        </tr>
    </tbody>
</table>

### Вывод

Результаты эксперимента показывают, что грамотная предобработка данных, тщательный подбор параметров и применение аугментации существенно повышают качество модели — что подтверждается улучшенным базовым решением. Дообучив YOLOv8 на материалах футбольных матчей, удалось добиться впечатляющих показателей. Такая модель может эффективно использоваться для анализа игровых действий футболистов и мониторинга матчей.
