# Лабораторные работы №6-8

------------------------------------------------
|  Выполнил    |    Группа       | Дата        |
|--------------|-----------------|-------------|
| Карнаков Н.Д.|    М8О-406Б-21  |   10.05.2025|

## Структура репозитория

[lab6-8MultiMediaSEM8.ipynb](lab6-8MultiMediaSEM8.ipynb) - Jupiter-notebook с выполненными лабораторными работами №6-8 

[README.md](README.md) - Краткий отчет о проделанной работе

## Лабораторная работа №6 (Проведение исследований с моделями классификации)

Используемый датасет для задачи классификации - https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia

### Сравнительная таблица 

| Model                              | Accuracy  | Precision | Recall   | F1-score | ROC-AUC  | PR-AUC   |
| ---------------------------------- | --------- | --------- | -------- | -------- | -------- | -------- |
| ResNet18 (baseline)                | 0.782051  | 0.746124  | 0.987179 | 0.849890 | 0.944587 | 0.959907 |
| ViT-B_16 (baseline)                | 0.727564  | 0.701465  | 0.982051 | 0.818376 | 0.932807 | 0.958099 |
| ResNet18 (improved)                | 0.931093  | 0.914081  | 0.982051 | 0.946848 | 0.975093 | 0.983458 |
| ViT-B_16 (improved)                | 0.868590  | 0.955621  | 0.828205 | 0.887363 | 0.960618 | 0.973207 |
| CustomCNN (baseline)               | 0.716346  | 0.689840  | 0.992308 | 0.813880 | 0.843809 | 0.854794 |
| CustomCNN (improved)               | 0.504808  | 0.987952  | 0.210256 | 0.346723 | 0.898619 | 0.933004 |
| Custom ViT (baseline)              | 0.625000  | 0.625000  | 1.000000 | 0.769231 | 0.500000 | 0.625000 |
| Custom ViT (improved)              | 0.625000  | 0.625000  | 1.000000 | 0.769231 | 0.500000 | 0.625000 |

На основе всестороннего эксперимента с восемью моделями для задачи бинарной классификации рентгеновских снимков лёгких была выявлена чёткая зависимость между предобученной архитектурой и объёмом обучающей выборки, а также эффективностью прикладных приёмов улучшения качества.

Во-первых, модели ResNet-18 и ViT-B_16, предобученные на ImageNet и использованные в качестве бейзлайна, продемонстрировали высокую базовую производительность: ResNet-18 показала сбалансированные метрики (accuracy ≈ 78 %, recall ≈ 99 %, precision ≈ 75 %, F1 ≈ 85 %), а ViT-B_16 чуть уступала ей по F1 (≈ 82 %), но уже обладала преимущественно высокой способностью к разделению классов (ROC-AUC ≈ 93 %). Применение комплекса улучшений — расширенные аугментации, взвешенная функция потерь и управление скоростью обучения через LR-scheduler — позволило ResNet-18 достичь accuracy ≈ 93 %, recall ≈ 98 % и precision ≈ 91 % (F1 ≈ 95 %), тогда как ViT-B_16 (improved) повысил precision до ≈ 96 % при F1 ≈ 89 %. Данные результаты подчёркивают, что предобученные на больших корпусах изображения CNN и трансформеры наиболее адекватно адаптируются к медицинским изображениям после донастройки.

Во-вторых, самостоятельная разработка сверточной нейронной сети (CustomCNN) с четырьмя блоками и двумя полносвязными слоями, обученная «с нуля» на том же ограниченном объёме данных, продемонстрировала высокий recall (≈ 99 %) за счёт массовых ложных срабатываний (precision ≈ 69 %, F1 ≈ 81 %), что свидетельствует о её склонности к максимизации полноты при минимальных объёмах. Попытка усилить модель аналогичным комплексом улучшений привела к обратному эффекту: precision возрос до ≈ 99 %, а recall упал до ≈ 21 %, что говорит о чрезмерной осторожности классификатора при отсутствии достаточной обучающей выборки.

В-третьих, собственная реализация Vision Transformer также показала крайне ограниченные возможности при обучении «с нуля» на 10 % данных: базовый Custom ViT практически всегда предсказывал один класс (accuracy ≈ 62 %, ROC-AUC = 0.5), а внесённые улучшения оказались бессильны сместить эту стагнацию. Это подчёркивает важность предобучения трансформеров на масштабных наборах данных и необходимости существенно большего объёма разнообразных медицинских изображений для их успешной адаптации.

Таким образом, результаты всего исследования позволяют заключить, что для задач классификации медицинских изображений при ограниченном объёме аннотированных данных оптимальным выбором являются предобученные архитектуры (ResNet, ViT) с дальнейшей донастройкой на целевом домене с применением техники аугментаций, балансировки классов и адаптивного изменения learning rate. Собственные модели без предобучения демонстрируют недостаточную способность к генерализации или, напротив, слишком радикальные компромиссы между recall и precision. Для дальнейшего улучшения качества классификации рекомендуется расширять аннотированные датасеты, использовать ансамбли предобученных архитектур и внедрять пороговую оптимизацию для достижения необходимого баланса между ошибками первого и второго рода.

## Лабораторная работа №7 (Проведение исследований моделями семантической сегментации).

В качестве метрик в задаче классификации использовались pixel accuracy, IoU и dice score. 
В таблице приведены получившиеся pixel accuracy, IoU и dice score для разных моделей.
<table>
    <thead>
        <tr>
            <th rowspan=2>Модель</th>
            <th colspan=2>Accuracy</th>
            <th colspan=2>IoU</th>
            <th colspan=2>Dice</th>
        </tr>
        <tr>
            <th>бейзлайн</th>
            <th>улучшенный бейзлайн</th>
            <th>бейзлайн</th>
            <th>улучшенный бейзлайн</th>
            <th>бейзлайн</th>
            <th>улучшенный бейзлайн</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><b><i>U-Net</i></b></td>
            <td>0.757</td>
            <td>0.872</td>
            <td>0.349</td>
            <td>0.480</td>
            <td>0.439</td>
            <td>0.566</td>
        </tr>
        <tr>
            <td><b><i>U-Net (собственной реализации)</i></b></td>
            <td>0.790</td>
            <td>0.782</td>
            <td>0.361</td>
            <td>0.317</td>
            <td>0.444</td>
            <td>0.374</td>
        </tr>
    </tbody>
</table>

### Вывод

Результаты показывают, что самой высокой точности в задаче семантической сегментации удалось добиться с помощью модели U-Net с энкодером ResNet50. При собственной реализации и тренировке стандартного бейзлайна удалось добиться показателей выше, чем у U-Net с энкодером ResNet34, однако улучшить бейзлайн в случае собственной реализации не удалось. Хоть в общем в процессе обучения лосс снижался, а значения основных метрик увеличивались, добиться значительного повышения точности не получилось. Стоило усложнить модель, так как изначальная реализация очень проста, и оптимизировать подбор гиперпараметров.

---

## Лабораторная работа №8 (Проведение исследований моделями обнаружения и распознавания объектов).

В качестве метрик в задаче классификации использовались Precision, Recall, mAP50, mAP50-95, которые автоматически рассчитывались во время тренировки модели.

В таблице приведены получившиеся Precision, Recall, mAP50, mAP50-95 для разных моделей.
<table>
    <thead>
        <tr>
            <th>Модель</th>
            <th>Precision</th>
            <th>Recall</th>
            <th>mAP50</th>
            <th>mAP50-95</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td><b><i>YOLOv8</i></b></td>
            <td>0.848</td>
            <td>0.702</td>
            <td>0.786</td>
            <td>0.494</td>
        </tr>
        <tr>
            <td><b><i>YOLOv8 с улучшенным бейзлайном</i></b></td>
            <td>0.901</td>
            <td>0.709</td>
            <td>0.800</td>
            <td>0.512</td>
        </tr>
    </tbody>
</table>

### Вывод

Полученные результаты подтверждают важность правильной предобработки данных, подбора параметров и аугментации для повышения качнства модели, что можно увидеть в улучшеном бейзлайне. Удалось получить очень хорошие результаты, дообучив модель YOLOv8 на данных футбольных матчей. Такая модель может быть успешно применима для анализа игры футболистов и наблюдения за матчами.
